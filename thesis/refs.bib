@inproceedings{article_deep_learning_framework_debt,
	author = {Liu, Jiakun and Huang, Qiao and Xia, Xin and Shihab, Emad and Lo,
	          David and Li, Shanping},
	title = {Is Using Deep Learning Frameworks Free? Characterizing Technical Debt
	         in Deep Learning Frameworks},
	year = {2020},
	month = {sept},
	day = {18},
	isbn = {9781450371254},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3377815.3381377},
	doi = {10.1145/3377815.3381377},
	abstract = {Developers of deep learning applications (shortened as application
	            developers) commonly use deep learning frameworks in their
	            projects. However, due to time pressure, market competition, and
	            cost reduction, developers of deep learning frameworks (shortened
	            as framework developers) often have to sacrifice software quality
	            to satisfy a shorter completion time. This practice leads to
	            technical debt in deep learning frameworks, which results in the
	            increasing burden to both the application developers and the
	            framework developers in future development.In this paper, we
	            analyze the comments indicating technical debt (self-admitted
	            technical debt) in 7 of the most popular open-source deep learning
	            frameworks. Although framework developers are aware of such
	            technical debt, typically the application developers are not. We
	            find that: 1) there is a significant number of technical debt in
	            all the studied deep learning frameworks. 2) there is design debt,
	            defect debt, documentation debt, test debt, requirement debt,
	            compatibility debt, and algorithm debt in deep learning frameworks.
	            3) the majority of the technical debt in deep learning framework is
	            design debt (24.07\% - 65.27\%), followed by requirement debt (7.09
	            \% - 31.48\%) and algorithm debt (5.62\% - 20.67\%). In some
	            projects, compatibility debt accounts for more than 10\%. These
	            findings illustrate that technicael debt is common in deep learning
	            frameworks, and many types of technical debt also impact the deep
	            learning applications. Based on our findings, we highlight future
	            research directions and provide recommendations for practitioners.},
	booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on
	             Software Engineering: Software Engineering in Society},
	pages = {1–10},
	numpages = {10},
	keywords = {self-admitted technical debt, deep learning, empirical study,
	            categorization},
	location = {Seoul, South Korea},
	series = {ICSE-SEIS '20},
	annotate = { Liu and their colleagues discuss the patterns of technical debt
	            found within popular open-sourced deep learning / machine learning
	            frameworks. They find and categorize the technical debt based on
	            comments left by the developers. The frameworks that they looked at
	            are mostly python based, however there are some frameworks listed
	            for Java and C\texttt{++}. There are some interesting conclusions
	            by looking at what types of debt that frameworks find themselves in
	            based on the language they are written in. },
}
@inproceedings{lang_rust,
	title = {The rust language},
	author = {Matsakis, Nicholas D and Klock II, Felix S},
	booktitle = {ACM SIGAda Ada Letters},
	volume = {34},
	number = {3},
	pages = {103--104},
	year = {2014},
	organization = {ACM},
} 
@book{lang_python,
	title = {Python tutorial},
	author = {Van Rossum, Guido and Drake Jr, Fred L},
	year = {1995},
	publisher = {Centrum voor Wiskunde en Informatica Amsterdam, The Netherlands},
}
@article{lib_numpy,
	title = {Array programming with {NumPy}},
	author = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J. van der
	          Walt and Ralf Gommers and Pauli Virtanen and David Cournapeau and
	          Eric Wieser and Julian Taylor and Sebastian Berg and Nathaniel J.
	          Smith and Robert Kern and Matti Picus and Stephan Hoyer and Marten H.
	          van Kerkwijk and Matthew Brett and Allan Haldane and Jaime Fern{\'{a}
	          }ndez del R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre G{\'
	          {e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and Warren
	          Weckesser and Hameer Abbasi and Christoph Gohlke and Travis E.
	          Oliphant},
	year = {2020},
	month = sep,
	journal = {Nature},
	volume = {585},
	number = {7825},
	pages = {357--362},
	doi = {10.1038/s41586-020-2649-2},
	publisher = {Springer Science and Business Media {LLC}},
	url = {https://doi.org/10.1038/s41586-020-2649-2},
}
@misc{lib_cuda,
	author = {NVIDIA and Vingelmann, Péter and Fitzek, Frank H.P.},
	title = {CUDA, release: 10.2.89},
	year = {2020},
	url = {https://developer.nvidia.com/cuda-toolkit},
}
@book{lang_c++,
	title = {The C++ programming language},
	author = {Stroustrup, Bjarne},
	year = {2000},
	publisher = {Pearson Education India},
}

@misc{lib_tensorflow,
	title = { {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
	url = {https://www.tensorflow.org/},
	note = {Software available from tensorflow.org},
	author = { Mart\'{i}n~Abadi and Ashish~Agarwal and Paul~Barham and Eugene~
	          Brevdo and Zhifeng~Chen and Craig~Citro and Greg~S.~Corrado and Andy~
	          Davis and Jeffrey~Dean and Matthieu~Devin and Sanjay~Ghemawat and Ian
	          ~Goodfellow and Andrew~Harp and Geoffrey~Irving and Michael~Isard and
	          Yangqing Jia and Rafal~Jozefowicz and Lukasz~Kaiser and Manjunath~
	          Kudlur and Josh~Levenberg and Dandelion~Man\'{e} and Rajat~Monga and
	          Sherry~Moore and Derek~Murray and Chris~Olah and Mike~Schuster and
	          Jonathon~Shlens and Benoit~Steiner and Ilya~Sutskever and Kunal~
	          Talwar and Paul~Tucker and Vincent~Vanhoucke and Vijay~Vasudevan and
	          Fernanda~Vi\'{e}gas and Oriol~Vinyals and Pete~Warden and Martin~
	          Wattenberg and Martin~Wicke and Yuan~Yu and Xiaoqiang~Zheng},
	year = {2015},
}
@software{lib_rayon,
	author = {Stone, Josh and Matsakis, Nico},
	title = {{Rayon: A data parallelism library for Rust}},
	url = {https://github.com/rayon-rs/rayon},
	year = {2015},
	version = "1.10.0"
}
@article{article_python_growing_language,
  title={Python--the fastest growing programming language},
  author={Srinath, KR},
  journal={International Research Journal of Engineering and Technology},
  volume={4},
  number={12},
  pages={354--357},
  year={2017}
}
@article{lib_pytorch,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}
@article{article_compiled_interpreted_hybrid_languages,
  title={Qualitative assessment of compiled, interpreted and hybrid programming languages},
  author={Kwame, Ampomah Ernest and Martey, Ezekiel Mensah and Chris, Abilimi Gilbert},
  journal={Communications on Applied Electronics},
  volume={7},
  number={7},
  pages={8--13},
  year={2017}
}
@manual{lang_r,
	title = {R: A Language and Environment for Statistical Computing},
	author = {{R Core Team}},
	organization = {R Foundation for Statistical Computing},
	address = {Vienna, Austria},
	year = {2021},
	url = {https://www.R-project.org/},
}
@article{article_cnn_survey,
  title={Convolutional neural networks: A survey},
  author={Krichen, Moez},
  journal={Computers},
  volume={12},
  number={8},
  pages={151},
  year={2023},
  publisher={MDPI}
}
@inproceedings{article_performance_analysis_gpu_cnn,
  title={Performance analysis of GPU-based convolutional neural networks},
  author={Li, Xiaqing and Zhang, Guangyan and Huang, H Howie and Wang, Zhufan and Zheng, Weimin},
  booktitle={2016 45th International conference on parallel processing (ICPP)},
  pages={67--76},
  year={2016},
  organization={IEEE}
}
@book{book_ml_for_dummies,
  title={Machine learning for dummies},
  author={Mueller, John Paul and Massaron, Luca},
  year={2021},
  publisher={John Wiley \& Sons}
}
@book{book_intro_neural_networks,
  title={An introduction to neural networks},
  author={Gurney, Kevin},
  year={2018},
  publisher={CRC press}
}
@book{lib_ggplot2,
	author = {Hadley Wickham},
	title = {ggplot2: Elegant Graphics for Data Analysis},
	publisher = {Springer-Verlag New York},
	year = {2016},
	isbn = {978-3-319-24277-4},
	url = {https://ggplot2.tidyverse.org},
}
