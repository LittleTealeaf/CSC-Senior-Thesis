\documentclass[12pt]{article}
\usepackage[numbers]{natbib}
\usepackage[margin=1in]{geometry}
\usepackage[nottoc]{tocbibind}
\usepackage{setspace}
\usepackage{svg}

\doublespacing

\author{Thomas Kwashnak}
\title{Senior Thesis}

\newcommand{\CC}{C\nolinebreak\hspace{-.05em}\raisebox{.4ex}{\tiny\bf +}\nolinebreak\hspace{-.10em}\raisebox{.4ex}{\tiny\bf + }}

\begin{document}

\maketitle

\newpage


\begin{itemize}
	\item Note, paragraphs are labeled, but labels will mostly be removed at the end
	\item Most of the paper is in bullet form. I spent most of this week working on the Data Science paper, so being able to write out each section shouldn't be too hard (Yes, I might have a long introduction... I had to do that for the Data Science paper too)
\end{itemize}


\section{Abstract}

\section{Introduction}

\paragraph{Intro Paragraph}
Machine learning is a quickly-growing industry with the recent boom of generative AI.
Many companies and organizations are quickly trying to use these machine learning frameworks for their own purposes.
However, these models are expensive, and can quickly spike up server cost to run.
These machine learning implementations are often using libraries such as TensorFlow \cite{lib_tensorflow} and PyTorch \cite{lib_pytorch} are often considered the standard for performing more complicated machine learning tasks.
These libraries handle a significant amount of the underlying methods used, and provide the ability to even utilize a GPU if it has the correct framework.
However, these libraries are mainly interacted with through the Python language \cite{lang_python}, which is often noted to be a slow language.

\paragraph{Review of Python as a growing language / use in Data Science}

Python has been one of the fastest growing languages in the industry today \cite{article_python_growing_language}.
Srinath, in their paper discussing Python's growing popularity, discusses several factors that lead to Python's success.
The Python language is an interpreted and dynamically typed language.
This, along with the very simple syntax, makes Python very quick to learn and start using.
It's highly extensible, and many mature libraries and frameworks that make even some complex tasks trivially easy to implement in Python.
One of the industries that Python continues to excel at is the data science and engineering community, where libraries in Python simplify working with databases or datasets.
The only drawback to Python is that it sacrifices speed for the ability to be as flexible as it is.
This can be partially mitigated, as Python allows building Python libraries from \CC  or other languages.
However, this doesn't fully eradicate the drawbacks to a dynamically typed interpreted language.

\paragraph{Review Compiled vs Interpreted Language}

There are three general types of translation modes for programming languages; interpreted, hybrid, and compiled \cite{article_compiled_interpreted_hybrid_languages}.
Python, and other similar languages, fall under the interpreted category.
Interpreted languages are typically taken line by line, executed immediately.
This allows for languages to be more portable as the interpreter interprets the inserted code, and runs machine level code based on the condition.
Hybrid languages include languages like Java.
The written code is first converted into byte-code, and then run on a virtual machine that can be platform dependant.
Compiled lanugages, such as C and \CC, compile code into machine-specific instructions that can be executed as is.
There are tradeoffs and benefits of using each these translation modes.
Interpreted and Hybrid languages are highly portable, as they rely on a virtual machine or the interpreter to convert code to device instructions.
However, they sacrifice execution time as additional checks and parsing happens when the program executes.
Compiled languages, however, are typically more strict with syntax, but they provide significantly better runtime performance than interpreted or hybrid languages.
That is to say, that code written in C and \CC are typcially faster to run than Python, but may be more difficult to impement or iterate on because of the language syntax and patterns.

\paragraph{Review of Deep Learning Framework Debt}

Libraries are pre-built collections of code that make it easier for developers to implement and perform certain tasks.
Often times, libraries are generalized to be used in a multitude of situations.
Thus, it's also important that these libraries are as efficient as they can be.
A recent study took a particular look into popular deep learning libraries, such as TensorFlow and PyTorch, and inspected the comments that indicate technical debt existing in the code \cite{article_deep_learning_framework_debt}.
The researchers categorized these indications of technical debt into categories; design debt, defect debt, documentation debt, test debt, requirement debt, compatability debt, and algorithm debt.
They found that the majority of technical debt found fell under design debt, followed by requirement debt and algorithm debt.
This indicates that there are a lot of areas within popular deep learning frameworks that the developers wish they had more time to fix, polish up, or change.
The conclusion is that these widely used libraries aren't without defects and shortcomings.
Thus indicating that use of these frameworks may assume some overhead.


\paragraph{Review of Neural Networks}

Neural networks is a category of mathematical models under machine learning that loosely attempts to mimick the brain \cite{book_intro_neural_networks}.
They are composed of nodes, or neurons, that accept multiple inputs from previous nodes, each value weighted by some unique weight, and outputs some value based on the inputs.
Neural networks have the ability to drastically increase its size, in turn increasing the time it may take to run the model on a given inputs.
The architecture of neural networks lends itself well to being represented using linear algebra, which itself lends nicely to parallelization and other optimizations.

% \paragraph{Review of Convolutional Neural Networks Survey}
% Neural networks are complicated models that are able 

\paragraph{Review of performance analysis of GPU CNN}

% Source \cite{article_performance_analysis_gpu_cnn}

\paragraph{Summarize the problem statement}

\paragraph{Discuss what this paper explores}

\section{Methods}

\paragraph{Initial Discussion of Methods}

To test the performance difference between manual implementations and the TensorFlow library, an identical algorithm was implemented in multiple different frameworks and languages.
This includes CUDA \cite{lib_cuda}, which runs on the GPU, TensorFlow \cite{lib_tensorflow}, which runs on either the GPU or CPU, and Rust \cite{lang_rust}, which acts as the CPU implementation.
While identical algorithms were not feasable to implement during the alloted time frame, each algorithm attempts to be as fast is it can be for the particular framework.
The algorithm chosen is a simple back-propagation neural network.
This allows for experimenting with the number of variables and size of the network, as well as the number of observations being concurrently processed at once.

\paragraph{Experiment design}

\begin{itemize}
	\item Discuss generated data
	\item Mention hardware used to test methods. Especially with WSL
	\item Discuss the parameters (number of iterations, sizes, etc) used for the data presented
	\item Either here or in every section discuss what is measured (loading data into GPU is not)
\end{itemize}

\paragraph{Data Generation}

How the data is generated (with the Python script)
\begin{itemize}
	\item Parameters / Configuration
	\item Sending it to files to be parsed by the implementations
	\item Discuss the scripts used to iteratively pass the data as environment parameters to each model (either here or in prior section)
\end{itemize}

\paragraph{Rust Implementation}

\begin{itemize}
	\item Custom implementation of back propagation (Unsure how far into detail I'll go here)
	\item Parallelized using Rayon \cite{lib_rayon} over observations (key point for discussion)
\end{itemize}

\paragraph{CUDA Implementation}


\begin{itemize}
	\item Implements a similar version to Rust's back propagation but slightly different
	\item Is multithreaded across all dimensions, including both the number of variables and the number of observations (Note: get better labels for these?)
\end{itemize}

\paragraph{Python (TensorFlow) implementation}

\begin{itemize}
	\item Network is built using variable tensors
	\item TensorFlow allows manually overriing the avalilable GPUs, so the TensorFlow implementation is used on both the GPU and CPU
\end{itemize}


\paragraph{Analysis Stage}


\begin{itemize}
	\item Data compounded into single dataset using bash script
	\item Data then loaded into R \cite{lang_r} and graphed using ggplot2 \cite{lib_ggplot2}.
\end{itemize}

\section{Results}

Yes, the figures need to be fixed

\begin{figure}
	\begin{center}
		\includesvg[width=0.8\linewidth]{svg/variables.svg}
	\end{center}
	\caption{Model training based on the variable count... (FINISH)}
\end{figure}

\begin{figure}
	\begin{center}
		\includesvg[width=0.8\linewidth]{svg/bootstraps.svg}
	\end{center}
	\caption{Model Training based on the observation size}
\end{figure}

\section{Discussion (and conclusion, but may push conclusion to separate section)}

Points to discuss:

\begin{itemize}
	\item Significant difference between CUDA and Tensorflow Performance
	\item Difference between TensorFlow and Rust implementations (Additional performance can still be gained in CPU implementation)
	\item Multithreading across observations was in all algorithms, so observation size did  not affect the runtime as much as the variable count
	\item Discuss that some of the difference between TensorFlow and CUDA is due to Python. additional exploration could include implementing TensorFlow (in Rust with their Rust bindings, or in C++)
	\item Discuss the amount of time needed to implement CUDA vs TensorFlow, maybe Rust but that sortof fell inbetween the two
\end{itemize}

\section{Conclusion}

\begin{itemize}
	\item TensorFlow excels at quick implementation and testing, and does it well enough
	\item However, in production for time-critical applications, manual implementations out-perform by a long shot.
	\item Sortof like a tradeoff between time spent in implementation and time spent in experimentation
\end{itemize}


\newpage
\bibliographystyle{ieeetr}
\bibliography{refs}

\end{document}
